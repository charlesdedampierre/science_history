{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26d4e60d-7d0a-42b3-997f-de9a3708fc9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "28600ac3-ff69-4280-b385-0532566812ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "\n",
    "from functions.env import DB_SCIENCE_PATH, FULL_DB_PATH\n",
    "from functions.feat_network import filter_edge_table, get_edge_node_table\n",
    "from functions.feat_optimization import (\n",
    "    get_mean,\n",
    "    get_rand_index,\n",
    "    get_rand_index_keep_identical,\n",
    ")\n",
    "from functions.feat_visualization import sygma_graph\n",
    "from networks.region_filters import columns_to_keep\n",
    "\n",
    "from networks.region_filters import columns_eu, columns_non_eu, columns_non_eu_unique\n",
    "\n",
    "conn = sqlite3.connect(DB_SCIENCE_PATH)\n",
    "conn_full_db = sqlite3.connect(FULL_DB_PATH)\n",
    "\n",
    "data_occupations = pd.read_sql(\"SELECT * FROM individual_id_cleaned_occupations\", conn)\n",
    "\n",
    "df_ind_regions = pd.read_sql_query(\n",
    "    \"SELECT * FROM individuals_regions\", conn_full_db\n",
    ")\n",
    "df_ind_regions = df_ind_regions.rename(\n",
    "    columns={\"individual_wikidata_id\": \"wikidata_id\"}\n",
    ")\n",
    "\n",
    "df_regions = df_ind_regions[[\"wikidata_id\", \"region_code\"]].drop_duplicates()\n",
    "df_regions = df_regions[df_regions[\"region_code\"].isin(columns_eu + columns_non_eu)]\n",
    "df_regions[\"region_code\"][df_regions[\"region_code\"].isin(columns_eu)] = \"re_europe\"\n",
    "\n",
    "df_regions = pd.merge(df_regions, data_occupations, on = 'wikidata_id')\n",
    "df_regions = df_regions.drop_duplicates()\n",
    "\n",
    "sample_size = 100\n",
    "data = df_regions.groupby(\"region_code\").sample(\n",
    "    sample_size, random_state=42, replace=True\n",
    ")\n",
    "data = data.drop('region_code', axis=1)\n",
    "\n",
    "data.columns = [\"source\", \"target\"]\n",
    "data[\"weight\"] = 1\n",
    "\n",
    "n_sample_individual = int(len(set(data.source)) / 10)\n",
    "batch_number = 20\n",
    "\n",
    "final_dict = []\n",
    "for n_neighbours in tqdm(np.arange(2, 5)):\n",
    "    for resolution in [1, 2]:\n",
    "        final_partition = []\n",
    "        for seed in np.arange(batch_number):\n",
    "            data_id = data[[\"source\"]].drop_duplicates()\n",
    "            data_id_sample = list(\n",
    "                data_id.sample(n_sample_individual, random_state=seed)[\n",
    "                    \"source\"\n",
    "                ]\n",
    "            )\n",
    "            df = data[data[\"source\"].isin(data_id_sample)]\n",
    "\n",
    "            df = pl.from_pandas(df)\n",
    "            df_edge, df_nodes = get_edge_node_table(df)\n",
    "\n",
    "            df_edge_filter = filter_edge_table(\n",
    "                df_edge,\n",
    "                edge_rule='count',\n",
    "                top_directed_neighbours=n_neighbours,\n",
    "                normalize_on_top=False,\n",
    "                min_count_link=1,\n",
    "            )\n",
    "\n",
    "            df_partition, g = sygma_graph(\n",
    "                df_edge_filter,\n",
    "                df_nodes,\n",
    "                edge_bins=5,\n",
    "                node_bins=10,\n",
    "                resolution=resolution,\n",
    "                filepath=\"../graph/cached_graph.html\",\n",
    "            )\n",
    "\n",
    "            df_partition = df_partition.rename(\n",
    "                columns={\"community\": f\"community_{seed}\"}\n",
    "            )\n",
    "            final_partition.append(df_partition)\n",
    "        # Merge the different clustering of the different samples together\n",
    "        merged_df = final_partition[0]\n",
    "        for df in final_partition[1:]:\n",
    "            merged_df = pd.merge(merged_df, df, on=\"node\", how=\"outer\")\n",
    "        merged_df = merged_df.set_index(\"node\")\n",
    "\n",
    "        final_list = []\n",
    "        for col in merged_df.columns:\n",
    "            list_community = list(merged_df[col])\n",
    "            final_list.append(list_community)\n",
    "\n",
    "        similarity_matrix = get_rand_index_keep_identical(final_list)\n",
    "        mean = get_mean(similarity_matrix)\n",
    "\n",
    "        new_dict = {\n",
    "            \"n_neighbours\": n_neighbours,\n",
    "            \"mean\": mean,\n",
    "            \"edge_rule\": edge_rule,\n",
    "            \"resolution\": resolution,\n",
    "            \"min_count_link\": min_count_link,\n",
    "        }\n",
    "\n",
    "        final_dict.append(new_dict)\n",
    "\n",
    "df_final = pd.DataFrame(final_dict)\n",
    "df_final[\"n_neighbours\"] = df_final[\"n_neighbours\"].astype(int)\n",
    "df_final = df_final.sort_values(\"mean\", ascending=False)\n",
    "df_final.to_sql(\n",
    "\"optimization_100_for_europe\", conn, if_exists=\"replace\", index=False\n",
    ")\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ea44947e-c8f4-483b-a8fe-0de1f70a5e65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 3/3 [00:35<00:00, 11.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   n_neighbours      mean edge_rule  resolution  min_count_link\n",
      "4             4  0.356153     count           1               1\n",
      "2             3  0.352078     count           1               1\n",
      "0             2  0.331843     count           1               1\n",
      "3             3  0.229561     count           2               1\n",
      "5             4  0.224100     count           2               1\n",
      "1             2  0.218820     count           2               1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2faa72-56c5-49cf-ab2f-032cb9fe7289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141bd280-bde6-428c-a4c3-9bd6dde84574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aca4db8-0e0f-4bfc-a149-bdc16eec98f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
