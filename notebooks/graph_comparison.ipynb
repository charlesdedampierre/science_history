{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4850a7a3-663d-4aba-8873-540771ec90ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the different graphs\n",
    "\n",
    "# Compare the pairwise clusters\n",
    "\n",
    "# What occupation belong the same clusters ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eedd7bf4-cf3f-46d0-a3ec-0fba2f937f56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a30c6943-860d-4f0c-9b81-d792a81cf35d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('region_gini_interets',), ('df_cleaned_occupations',), ('individual_id_cleaned_occupations',), ('temporal_data',), ('optimization',), ('region_optimized_partition',), ('temporal_data_clean',), ('individual_score',), ('optimal_partition',), ('partition_before_1500',), ('partition_global',), ('partition_non_europe',), ('partition_top_individuals',), ('optimal_partition_weighted',)]\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"../database.db\")\n",
    "sql_query = \"\"\"SELECT name FROM sqlite_master WHERE type='table';\"\"\"\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(sql_query)\n",
    "print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f026756e-881f-418f-9a4d-7e8126f054e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f56eb055-1d1e-40a3-af39-63b5e66c1d0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_partition_before_1500 = pd.read_sql(\"SELECT * FROM partition_before_1500\", conn)\n",
    "df_partition_before_1500 = df_partition_before_1500.sort_values('node', ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_partition_non_europe = pd.read_sql(\"SELECT * FROM partition_non_europe\", conn)\n",
    "df_partition_non_europe = df_partition_non_europe.sort_values('node', ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_partition_top_individuals = pd.read_sql(\"SELECT * FROM partition_top_individuals\", conn)\n",
    "df_partition_top_individuals = df_partition_top_individuals.sort_values('node', ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_partition_global = pd.read_sql(\"SELECT * FROM partition_global\", conn)\n",
    "df_partition_global = df_partition_global.sort_values('node', ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_optimal_partition_weighted =  pd.read_sql(\"SELECT * FROM optimal_partition_weighted \", conn)\n",
    "df_optimal_partition_weighted = df_optimal_partition_weighted.sort_values('node', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739b699d-e986-4451-a85a-8cd31f0ea205",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a502da-76d6-4017-b91f-a8ea99fd41cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e85ff4a-b796-4e44-9621-79365733c9b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_90205/3431362841.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_90205/3431362841.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_90205/3431362841.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_90205/3431362841.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_90205/3431362841.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_90205/3431362841.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_90205/3431362841.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_90205/3431362841.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_90205/3431362841.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_90205/3431362841.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_90205/3431362841.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_90205/3431362841.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_90205/3431362841.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_90205/3431362841.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_90205/3431362841.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_90205/3431362841.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_90205/3431362841.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_90205/3431362841.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_90205/3431362841.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_90205/3431362841.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "\n",
    "# Assuming you've loaded your datasets as described in the question\n",
    "\n",
    "datasets = {\n",
    "    'Before 1500': df_partition_before_1500,\n",
    "    'Non-Europe': df_partition_non_europe,\n",
    "    'Top Individuals': df_partition_top_individuals,\n",
    "    'Global': df_partition_global,\n",
    "    'Weighted': df_optimal_partition_weighted\n",
    "}\n",
    "\n",
    "# Create an empty DataFrame to store the ARI values\n",
    "ari_df = pd.DataFrame(columns=['Dataset 1', 'Dataset 2', 'ARI'])\n",
    "\n",
    "\n",
    "# Iterate over pairs of datasets and compute the ARI\n",
    "for dataset1_name, dataset1 in datasets.items():\n",
    "    for dataset2_name, dataset2 in datasets.items():\n",
    "        if dataset1_name != dataset2_name:\n",
    "            # Get the common elements based on the 'node' column\n",
    "            common_elements = set(dataset1['node']).intersection(dataset2['node'])\n",
    "            \n",
    "            # Filter the datasets to include only the common elements\n",
    "            filtered_dataset1 = dataset1[dataset1['node'].isin(common_elements)]\n",
    "            filtered_dataset2 = dataset2[dataset2['node'].isin(common_elements)]\n",
    "            \n",
    "            ari = adjusted_rand_score(filtered_dataset1['community'], filtered_dataset2['community'])\n",
    "            ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
    "\n",
    "# Print or analyze the ARI values as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4812de29-5df7-472f-bd49-4c17542d33d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3209026-17ba-4981-b5e6-aadba6bacd99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6978431725921397"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ari_df.ARI.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a86da210-a881-4e81-8631-4a6653cda258",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataset 2</th>\n",
       "      <th>Before 1500</th>\n",
       "      <th>Global</th>\n",
       "      <th>Non-Europe</th>\n",
       "      <th>Top Individuals</th>\n",
       "      <th>Weighted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset 1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before 1500</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.563659</td>\n",
       "      <td>0.554548</td>\n",
       "      <td>0.757737</td>\n",
       "      <td>0.650404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Global</th>\n",
       "      <td>0.563659</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.690539</td>\n",
       "      <td>0.704312</td>\n",
       "      <td>0.895031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-Europe</th>\n",
       "      <td>0.554548</td>\n",
       "      <td>0.690539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.593429</td>\n",
       "      <td>0.783887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top Individuals</th>\n",
       "      <td>0.757737</td>\n",
       "      <td>0.704312</td>\n",
       "      <td>0.593429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.784885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weighted</th>\n",
       "      <td>0.650404</td>\n",
       "      <td>0.895031</td>\n",
       "      <td>0.783887</td>\n",
       "      <td>0.784885</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset 2        Before 1500    Global  Non-Europe  Top Individuals  Weighted\n",
       "Dataset 1                                                                    \n",
       "Before 1500         1.000000  0.563659    0.554548         0.757737  0.650404\n",
       "Global              0.563659  1.000000    0.690539         0.704312  0.895031\n",
       "Non-Europe          0.554548  0.690539    1.000000         0.593429  0.783887\n",
       "Top Individuals     0.757737  0.704312    0.593429         1.000000  0.784885\n",
       "Weighted            0.650404  0.895031    0.783887         0.784885  1.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_df = ari_df.pivot_table(index='Dataset 1', columns='Dataset 2', values='ARI', aggfunc='mean')\n",
    "matrix_df = matrix_df.fillna(1)\n",
    "matrix_df.to_clipboard()\n",
    "matrix_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f76d0a3-7acc-4a44-a558-508147fb0229",
   "metadata": {},
   "source": [
    "#### Find the pair that always tsay together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dba09e99-b958-43ae-a62b-71a236b8e6c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sample datasets\n",
    "dataset1 = datasets['Global']\n",
    "dataset1.columns = ['node', 'com1']\n",
    "\n",
    "dataset2 = datasets['Before 1500']\n",
    "dataset2.columns = ['node', 'com2']\n",
    "\n",
    "dataset3 = datasets['Weighted']\n",
    "dataset3.columns = ['node', 'com3']\n",
    "\n",
    "dataset4 = datasets['Top Individuals']\n",
    "dataset4.columns = ['node', 'com4']\n",
    "\n",
    "dataset5 = datasets['Non-Europe']\n",
    "dataset5.columns = ['node', 'com5']\n",
    "\n",
    "df = pd.merge(dataset1, dataset2, on = 'node')\n",
    "df = pd.merge(df, dataset3, on = 'node')\n",
    "df = pd.merge(df, dataset4, on = 'node')\n",
    "df = pd.merge(df, dataset5, on = 'node')\n",
    "\n",
    "final = []\n",
    "for occ_1 in list(df.node):\n",
    "    for occ_2 in list(df.node):\n",
    "        if occ_1 == occ_2:\n",
    "            pass\n",
    "        else:\n",
    "            res = df[df['node'].isin([occ_1, occ_2])]\n",
    "            \n",
    "            count_elements = []\n",
    "            for col in df.columns[1:]:\n",
    "                count_element = len(set(list(res[col])))\n",
    "                count_elements.append(count_element)\n",
    "                \n",
    "            if count_elements == [1,1,1,1,1]:\n",
    "                final.append({'occ_1':occ_1, 'occ_2':occ_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1270068b-53a9-4e3f-b197-38306362e90a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test =pd.DataFrame(final)\n",
    "len(set(test.occ_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b907b4f9-2889-4f93-8827-6842b40eb8c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f7e033-1e75-4959-8267-45aca40d0ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e0e0c3-6463-4c53-afe7-91d084f9cc86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
