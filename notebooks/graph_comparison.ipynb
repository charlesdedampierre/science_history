{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4850a7a3-663d-4aba-8873-540771ec90ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the different graphs\n",
    "\n",
    "# Compare the pairwise clusters\n",
    "\n",
    "# What occupation belong the same clusters ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eedd7bf4-cf3f-46d0-a3ec-0fba2f937f56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a30c6943-860d-4f0c-9b81-d792a81cf35d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('region_gini_interets',), ('df_cleaned_occupations',), ('individual_id_cleaned_occupations',), ('temporal_data',), ('optimization',), ('temporal_data_clean',), ('individual_score',), ('optimal_partition',), ('partition_global',), ('partition_top_individuals',), ('optimal_partition_weighted',), ('partition_after_1500_weighted',), ('partition_before_1500_weighted',), ('partition_after_1500',), ('partition_after_1600',), ('wiki_abtract',), ('partition_after_1800_europe',), ('partition_non_europe_optimization_100',), ('partition_non_europe_before_800',), ('partition_non_europe_before_900',), ('partition_non_europe_before_1000',), ('partition_non_europe_before_1100',), ('partition_non_europe_before_1200',), ('partition_non_europe_before_1300',), ('partition_non_europe_before_1400',), ('partition_non_europe_before_1500',), ('partition_non_europe_before_1600',), ('partition_non_europe_before_1700',), ('partition_non_europe_before_1800',), ('partition_non_europe_before_1900',), ('partition_non_europe_params_optimized',), ('optimal_partition_weighted_optimized_100__europe_as_on',), ('optimization_europe_before_1500',), ('partition_before_1500',), ('optimization_non_europe',), ('optimization_100',), ('optimization_100_for_europe',), ('optimization_europe',), ('optimal_partition_weighted_optimized_100_europe_as_on',), ('partition_europe_before_800',), ('partition_europe_before_900',), ('partition_europe_before_1000',), ('partition_europe_before_1100',), ('partition_europe_before_1200',), ('partition_europe_before_1300',), ('partition_europe_before_1400',), ('partition_europe_before_1500',), ('partition_europe_before_1600',), ('partition_europe_before_1700',), ('partition_europe_before_1800',), ('partition_europe_before_1900',), ('region_optimized_partition',), ('partition_non_europe',), ('optimal_partition_weighted_optimized_100',), ('partition_europe',), ('optimal_partition_100_europe',), ('partition_before_1600',)]\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"../database.db\")\n",
    "sql_query = \"\"\"SELECT name FROM sqlite_master WHERE type='table';\"\"\"\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(sql_query)\n",
    "print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabcf586-e8da-4fe6-bb02-f524b445e5dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f56eb055-1d1e-40a3-af39-63b5e66c1d0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_partition_before_1500 = pd.read_sql(\"SELECT * FROM partition_before_1600\", conn)\n",
    "df_partition_before_1500 = df_partition_before_1500.sort_values('node', ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_partition_after_1500 = pd.read_sql(\"SELECT * FROM partition_after_1600\", conn)\n",
    "df_partition_after_1500 = df_partition_after_1500.sort_values('node', ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_partition_non_europe = pd.read_sql(\"SELECT * FROM partition_non_europe\", conn)\n",
    "df_partition_non_europe = df_partition_non_europe.sort_values('node', ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_partition_europe = pd.read_sql(\"SELECT * FROM partition_europe\", conn)\n",
    "df_partition_europe = df_partition_europe.sort_values('node', ascending=False).reset_index(drop=True)\n",
    "\n",
    "#df_partition_top_individuals = pd.read_sql(\"SELECT * FROM partition_top_individuals\", conn)\n",
    "#df_partition_top_individuals = df_partition_top_individuals.sort_values('node', ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_partition_global = pd.read_sql(\"SELECT * FROM partition_global\", conn)\n",
    "df_partition_global = df_partition_global.sort_values('node', ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_optimal_partition_weighted =  pd.read_sql(\"SELECT * FROM optimal_partition_100_europe \", conn)\n",
    "df_optimal_partition_weighted = df_optimal_partition_weighted.sort_values('node', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f02e9da-15bc-4d05-8f96-9129b0dcfc99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a502da-76d6-4017-b91f-a8ea99fd41cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e85ff4a-b796-4e44-9621-79365733c9b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_53843/1060566217.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_53843/1060566217.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_53843/1060566217.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_53843/1060566217.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_53843/1060566217.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_53843/1060566217.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_53843/1060566217.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_53843/1060566217.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_53843/1060566217.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_53843/1060566217.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_53843/1060566217.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
      "/var/folders/lx/9b13r6ln63jb54_3xlf9b_380000gn/T/ipykernel_53843/1060566217.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "\n",
    "# Assuming you've loaded your datasets as described in the question\n",
    "\n",
    "datasets = {\n",
    "    'Before 1600': df_partition_before_1500,\n",
    "    #'After 1600': df_partition_after_1500,\n",
    "     'Europe': df_partition_europe,\n",
    "    'Non-Europe': df_partition_non_europe,\n",
    "    #'Top Individuals': df_partition_top_individuals,\n",
    "    #'Global': df_partition_global,\n",
    "    'Weighted': df_optimal_partition_weighted\n",
    "}\n",
    "\n",
    "# Create an empty DataFrame to store the ARI values\n",
    "ari_df = pd.DataFrame(columns=['Dataset 1', 'Dataset 2', 'ARI'])\n",
    "\n",
    "\n",
    "# Iterate over pairs of datasets and compute the ARI\n",
    "for dataset1_name, dataset1 in datasets.items():\n",
    "    for dataset2_name, dataset2 in datasets.items():\n",
    "        if dataset1_name != dataset2_name:\n",
    "            # Get the common elements based on the 'node' column\n",
    "            common_elements = set(dataset1['node']).intersection(dataset2['node'])\n",
    "            \n",
    "            # Filter the datasets to include only the common elements\n",
    "            filtered_dataset1 = dataset1[dataset1['node'].isin(common_elements)]\n",
    "            filtered_dataset2 = dataset2[dataset2['node'].isin(common_elements)]\n",
    "            \n",
    "            ari = adjusted_rand_score(filtered_dataset1['community'], filtered_dataset2['community'])\n",
    "            ari_df = ari_df.append({'Dataset 1': dataset1_name, 'Dataset 2': dataset2_name, 'ARI': ari}, ignore_index=True)\n",
    "\n",
    "# Print or analyze the ARI values as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3209026-17ba-4981-b5e6-aadba6bacd99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6225856378780326"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ari_df.ARI.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a86da210-a881-4e81-8631-4a6653cda258",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataset 2</th>\n",
       "      <th>Before 1600</th>\n",
       "      <th>Europe</th>\n",
       "      <th>Non-Europe</th>\n",
       "      <th>Weighted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset 1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before 1600</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.558376</td>\n",
       "      <td>0.474823</td>\n",
       "      <td>0.596211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Europe</th>\n",
       "      <td>0.558376</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.738783</td>\n",
       "      <td>0.546139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-Europe</th>\n",
       "      <td>0.474823</td>\n",
       "      <td>0.738783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.821182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weighted</th>\n",
       "      <td>0.596211</td>\n",
       "      <td>0.546139</td>\n",
       "      <td>0.821182</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset 2    Before 1600    Europe  Non-Europe  Weighted\n",
       "Dataset 1                                               \n",
       "Before 1600     1.000000  0.558376    0.474823  0.596211\n",
       "Europe          0.558376  1.000000    0.738783  0.546139\n",
       "Non-Europe      0.474823  0.738783    1.000000  0.821182\n",
       "Weighted        0.596211  0.546139    0.821182  1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_df = ari_df.pivot_table(index='Dataset 1', columns='Dataset 2', values='ARI', aggfunc='mean')\n",
    "matrix_df = matrix_df.fillna(1)\n",
    "matrix_df.to_clipboard()\n",
    "matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48be79b5-e6cd-48f3-b3b7-492c1c5c0b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5477f7af-4e0a-4d8c-a6bf-ed58e4689fae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f76d0a3-7acc-4a44-a558-508147fb0229",
   "metadata": {},
   "source": [
    "#### Find the pair that always tsay together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dba09e99-b958-43ae-a62b-71a236b8e6c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Global'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Sample datasets\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dataset1 \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGlobal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m dataset1\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnode\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcom1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m dataset2 \u001b[38;5;241m=\u001b[39m datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBefore 1500\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Global'"
     ]
    }
   ],
   "source": [
    "# Sample datasets\n",
    "dataset1 = datasets['Global']\n",
    "dataset1.columns = ['node', 'com1']\n",
    "\n",
    "dataset2 = datasets['Before 1500']\n",
    "dataset2.columns = ['node', 'com2']\n",
    "\n",
    "dataset3 = datasets['Weighted']\n",
    "dataset3.columns = ['node', 'com3']\n",
    "\n",
    "dataset4 = datasets['Top Individuals']\n",
    "dataset4.columns = ['node', 'com4']\n",
    "\n",
    "dataset5 = datasets['Non-Europe']\n",
    "dataset5.columns = ['node', 'com5']\n",
    "\n",
    "df = pd.merge(dataset1, dataset2, on = 'node')\n",
    "df = pd.merge(df, dataset3, on = 'node')\n",
    "df = pd.merge(df, dataset4, on = 'node')\n",
    "df = pd.merge(df, dataset5, on = 'node')\n",
    "\n",
    "final = []\n",
    "for occ_1 in list(df.node):\n",
    "    for occ_2 in list(df.node):\n",
    "        if occ_1 == occ_2:\n",
    "            pass\n",
    "        else:\n",
    "            res = df[df['node'].isin([occ_1, occ_2])]\n",
    "            \n",
    "            count_elements = []\n",
    "            for col in df.columns[1:]:\n",
    "                count_element = len(set(list(res[col])))\n",
    "                count_elements.append(count_element)\n",
    "                \n",
    "            if count_elements == [1,1,1,1,1]:\n",
    "                final.append({'occ_1':occ_1, 'occ_2':occ_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1270068b-53a9-4e3f-b197-38306362e90a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test =pd.DataFrame(final)\n",
    "len(set(test.occ_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b907b4f9-2889-4f93-8827-6842b40eb8c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f7e033-1e75-4959-8267-45aca40d0ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e0e0c3-6463-4c53-afe7-91d084f9cc86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
